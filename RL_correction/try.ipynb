{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0b82b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching reference HEAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI2-THOR WARNING] There has been an update to ProcTHOR-10K that must be used with AI2-THOR version 5.0+. To use the new version of ProcTHOR-10K, please update AI2-THOR to version 5.0+ by running:\n",
      "    pip install --upgrade ai2thor\n",
      "Alternatively, to downgrade to the old version of ProcTHOR-10K, run:\n",
      "   prior.load_dataset(\"procthor-10k\", revision=\"ab3cacd0fc17754d4c080a3fd50b18395fae8647\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 23029.32it/s]\n",
      "Loading val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 23938.86it/s]\n",
      "Loading test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 24483.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict(\n",
       "    train=Dataset(\n",
       "    dataset=procthor-dataset,\n",
       "    size=10000,\n",
       "    split=train\n",
       "),\n",
       "    val=Dataset(\n",
       "    dataset=procthor-dataset,\n",
       "    size=1000,\n",
       "    split=val\n",
       "),\n",
       "    test=Dataset(\n",
       "    dataset=procthor-dataset,\n",
       "    size=1000,\n",
       "    split=test\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prior\n",
    "\n",
    "dataset = prior.load_dataset(\"procthor-10k\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22917828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai2thor.controller import Controller\n",
    "\n",
    "\n",
    "house = dataset[\"train\"][3]\n",
    "controller = Controller(scene=house, snapToGrid=False, rotateStepDegrees=30)\n",
    "event = controller.step(\"Pass\")\n",
    "spawn = event.metadata[\"agent\"][\"position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a011a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def teleport(controller, target=None):\n",
    "    event = controller.step(\"GetReachablePositions\")\n",
    "    reachable_positions = event.metadata[\"actionReturn\"]\n",
    "    # Pick a random target\n",
    "    if target is None:\n",
    "        target = np.random.choice(reachable_positions)\n",
    "\n",
    "    event = controller.step(\n",
    "        action=\"TeleportFull\",\n",
    "        x=target[\"x\"],\n",
    "        y=target[\"y\"],\n",
    "        z=target[\"z\"],\n",
    "        rotation={\"x\": 0, \"y\": 0, \"z\": 0},\n",
    "        horizon=0,\n",
    "        standing=True\n",
    "    )\n",
    "\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d347af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl import PPO, ActorCritic, Env, RolloutBuffer, ClipEnv, CLIPNovelty\n",
    "from models import LSTMActor, LSTMCritic, FrozenResNetEncoder, SlidingWindowTransformerActor, SlidingWindowTransformerCritic\n",
    "from cons import MINIBATCHES, EPISODE_STEPS, FEAT_DIM, NUM_ACTIONS, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7133071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from rl import save_actor_critic\n",
    "\n",
    "def train(controller, name: str, ppo: PPO, env: Env, actor_critic: ActorCritic, total_updates=10):\n",
    "    event = controller.step(\"Pass\")  # prime\n",
    "    rewards = []\n",
    "    episode_rewards = []\n",
    "    for upd in range(total_updates):\n",
    "        buf = RolloutBuffer()\n",
    "        for mb in range(MINIBATCHES):\n",
    "            # collect episodes\n",
    "            episode_seq = []\n",
    "            episode_reward = 0\n",
    "            actions_seq = []\n",
    "            for t in range(1, EPISODE_STEPS + 1):\n",
    "                with torch.no_grad():\n",
    "                    obs_t = ppo.obs_from_event(event)  # (C,H,W)\n",
    "                    obs_encoded = actor_critic.actor_critic_encoder(obs_t.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0) # (D)\n",
    "                    obs_seq = torch.stack(episode_seq + [obs_encoded], dim=0).to(device=DEVICE)\n",
    "\n",
    "                if len(actions_seq) == 0:\n",
    "                    actions_seq.append(torch.randint(0, NUM_ACTIONS, (1, 1)).item())\n",
    "                \n",
    "                actions_tensor = torch.tensor(actions_seq, dtype=torch.long, device=DEVICE)\n",
    "                logits, value = ppo.act_and_value(obs_seq, actions_tensor, actor_critic)\n",
    "                dist = torch.distributions.Categorical(logits=logits)\n",
    "                action_idx = dist.sample()\n",
    "                logp = dist.log_prob(action_idx)\n",
    "                \n",
    "                action_idx, logp = action_idx.item(), logp.item()\n",
    "                event, reward = env.step_env(controller, action_idx)\n",
    "                done = t == EPISODE_STEPS\n",
    "\n",
    "                # store one step\n",
    "                buf.add(obs_t, action_idx, logp, reward, value, done)\n",
    "                episode_seq.append(obs_encoded)\n",
    "                rewards.append(reward)\n",
    "                actions_seq.append(action_idx)\n",
    "                \n",
    "                episode_reward += reward / EPISODE_STEPS\n",
    "\n",
    "                # 50% chance of teleport\n",
    "                if done:\n",
    "                    env.reset()\n",
    "                    if np.random.rand() > 0.5:\n",
    "                        event = teleport(controller)\n",
    "            episode_rewards.append(episode_reward)\n",
    "                \n",
    "        ppo.ppo_update(buf, actor_critic)\n",
    "        save_actor_critic(actor_critic, name)\n",
    "        \n",
    "        print(f\"Update {upd+1}/{total_updates} â€” steps: {len(buf)}\")\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        plt.plot(episode_rewards)\n",
    "        plt.show()\n",
    "    return buf, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc1948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTROPY_COEF = 0.05\n",
    "\n",
    "ppo = PPO(ENTROPY_COEF)\n",
    "encoder = FrozenResNetEncoder()\n",
    "actor = SlidingWindowTransformerActor(FEAT_DIM, NUM_ACTIONS)\n",
    "critic = SlidingWindowTransformerCritic(FEAT_DIM)\n",
    "clip_novelty = CLIPNovelty()\n",
    "clip_env = ClipEnv(clip_novelty)\n",
    "clip_actor_critic = ActorCritic(encoder, actor, critic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3da78fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PPO_CLIP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m buf, rewards \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclip_actor_critic_checkpoint_long_training.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_actor_critic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(controller, name, ppo, env, actor_critic, total_updates)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 event \u001b[38;5;241m=\u001b[39m teleport(controller)\n\u001b[1;32m     48\u001b[0m     episode_rewards\u001b[38;5;241m.\u001b[39mappend(episode_reward)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mppo_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_critic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m save_actor_critic(actor_critic, name)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupd\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_updates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m â€” steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(buf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 124\u001b[0m, in \u001b[0;36mPPO.ppo_update\u001b[0;34m(self, buffer, actor_critic)\u001b[0m\n\u001b[1;32m    122\u001b[0m ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(new_logp \u001b[38;5;241m-\u001b[39m old_logps)\n\u001b[1;32m    123\u001b[0m surr1 \u001b[38;5;241m=\u001b[39m ratio \u001b[38;5;241m*\u001b[39m advantages\n\u001b[0;32m--> 124\u001b[0m surr2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(ratio, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mPPO_CLIP\u001b[49m, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m PPO_CLIP) \u001b[38;5;241m*\u001b[39m advantages\n\u001b[1;32m    125\u001b[0m policy_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmin(surr1, surr2)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Value and entropy losses\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PPO_CLIP' is not defined"
     ]
    }
   ],
   "source": [
    "buf, rewards = train(controller, \"clip_actor_critic_checkpoint_long_training.pt\", ppo, clip_env, clip_actor_critic, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00b8065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (300, 300) to (304, 304) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ðŸŽžï¸] Saved video to rollout.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0985212326049805, 1.6973028182983398],\n",
       " [1.0985212326049805, 1.9473028182983398],\n",
       " [1.0985212326049805, 2.19730281829834],\n",
       " [1.0985212326049805, 2.44730281829834],\n",
       " [1.0985212326049805, 2.44730281829834],\n",
       " [0.9735212326049805, 2.663809061050415],\n",
       " [0.9735212326049805, 2.663809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 2.788809061050415],\n",
       " [0.7570148706436157, 3.038809061050415],\n",
       " [0.7570148706436157, 3.038809061050415],\n",
       " [0.8820148706436157, 3.2553153038024902],\n",
       " [0.8820148706436157, 3.2553153038024902],\n",
       " [1.0985212326049805, 3.3803153038024902],\n",
       " [1.0985212326049805, 3.3803153038024902],\n",
       " [1.0985212326049805, 3.3803153038024902],\n",
       " [1.0985212326049805, 3.6303153038024902],\n",
       " [1.0985212326049805, 3.8803153038024902],\n",
       " [1.0985212326049805, 3.8803153038024902],\n",
       " [1.0985212326049805, 3.8803153038024902],\n",
       " [1.0985212326049805, 4.13031530380249],\n",
       " [1.0985212326049805, 4.38031530380249],\n",
       " [1.0985212326049805, 4.38031530380249],\n",
       " [1.0985212326049805, 4.38031530380249],\n",
       " [1.3150275945663452, 4.50531530380249],\n",
       " [1.53153395652771, 4.63031530380249],\n",
       " [1.7480403184890747, 4.75531530380249],\n",
       " [1.7480403184890747, 4.75531530380249],\n",
       " [1.9980403184890747, 4.75531530380249],\n",
       " [2.248040199279785, 4.75531530380249],\n",
       " [2.498040199279785, 4.75531530380249],\n",
       " [2.748040199279785, 4.75531530380249],\n",
       " [2.998040199279785, 4.75531530380249],\n",
       " [3.248040199279785, 4.75531530380249],\n",
       " [3.248040199279785, 4.75531530380249],\n",
       " [3.4645464420318604, 4.63031530380249],\n",
       " [3.6810526847839355, 4.50531530380249],\n",
       " [3.6810526847839355, 4.50531530380249],\n",
       " [3.9310526847839355, 4.50531530380249],\n",
       " [4.1810526847839355, 4.50531530380249],\n",
       " [4.4310526847839355, 4.50531530380249],\n",
       " [4.6810526847839355, 4.50531530380249],\n",
       " [4.9310526847839355, 4.50531530380249],\n",
       " [5.1810526847839355, 4.50531530380249],\n",
       " [5.4310526847839355, 4.50531530380249],\n",
       " [5.6810526847839355, 4.50531530380249],\n",
       " [5.9310526847839355, 4.50531530380249],\n",
       " [6.1810526847839355, 4.50531530380249],\n",
       " [6.4310526847839355, 4.50531530380249],\n",
       " [6.6810526847839355, 4.50531530380249],\n",
       " [6.9310526847839355, 4.50531530380249],\n",
       " [7.1810526847839355, 4.50531530380249],\n",
       " [7.4310526847839355, 4.50531530380249],\n",
       " [7.6810526847839355, 4.50531530380249],\n",
       " [7.6810526847839355, 4.50531530380249],\n",
       " [7.89755916595459, 4.38031530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [8.114065170288086, 4.25531530380249],\n",
       " [7.864065170288086, 4.25531530380249],\n",
       " [7.614065170288086, 4.25531530380249],\n",
       " [7.364065170288086, 4.25531530380249],\n",
       " [7.114065170288086, 4.25531530380249],\n",
       " [6.864065170288086, 4.25531530380249],\n",
       " [6.614065170288086, 4.25531530380249],\n",
       " [6.364065170288086, 4.25531530380249],\n",
       " [6.114065170288086, 4.25531530380249],\n",
       " [5.864065170288086, 4.25531530380249],\n",
       " [5.614065170288086, 4.25531530380249],\n",
       " [5.364065170288086, 4.25531530380249],\n",
       " [5.114065170288086, 4.25531530380249],\n",
       " [4.864065170288086, 4.25531530380249],\n",
       " [4.614065170288086, 4.25531530380249],\n",
       " [4.364065170288086, 4.25531530380249],\n",
       " [4.114065170288086, 4.25531530380249],\n",
       " [3.864065170288086, 4.25531530380249],\n",
       " [3.614065170288086, 4.25531530380249],\n",
       " [3.364065170288086, 4.25531530380249],\n",
       " [3.114065170288086, 4.25531530380249],\n",
       " [2.864065170288086, 4.25531530380249],\n",
       " [2.614065170288086, 4.25531530380249],\n",
       " [2.614065170288086, 4.25531530380249],\n",
       " [2.614065170288086, 4.25531530380249],\n",
       " [2.614065170288086, 4.25531530380249],\n",
       " [2.614065170288086, 4.25531530380249],\n",
       " [2.364065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.114065170288086, 4.25531530380249],\n",
       " [2.3305716514587402, 4.38031530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.5470781326293945, 4.50531530380249],\n",
       " [2.7970781326293945, 4.50531530380249],\n",
       " [3.0470781326293945, 4.50531530380249],\n",
       " [3.2970781326293945, 4.50531530380249],\n",
       " [3.5470781326293945, 4.50531530380249],\n",
       " [3.7970781326293945, 4.50531530380249],\n",
       " [4.0470781326293945, 4.50531530380249],\n",
       " [4.2970781326293945, 4.50531530380249],\n",
       " [4.5470781326293945, 4.50531530380249],\n",
       " [4.7970781326293945, 4.50531530380249],\n",
       " [5.0470781326293945, 4.50531530380249],\n",
       " [5.2970781326293945, 4.50531530380249],\n",
       " [5.5470781326293945, 4.50531530380249],\n",
       " [5.7970781326293945, 4.50531530380249],\n",
       " [6.0470781326293945, 4.50531530380249],\n",
       " [6.2970781326293945, 4.50531530380249],\n",
       " [6.5470781326293945, 4.50531530380249],\n",
       " [6.7970781326293945, 4.50531530380249],\n",
       " [7.0470781326293945, 4.50531530380249],\n",
       " [7.2970781326293945, 4.50531530380249],\n",
       " [7.5470781326293945, 4.50531530380249],\n",
       " [7.7970781326293945, 4.50531530380249],\n",
       " [7.7970781326293945, 4.50531530380249],\n",
       " [8.01358413696289, 4.38031530380249],\n",
       " [8.01358413696289, 4.38031530380249],\n",
       " [8.13858413696289, 4.163808822631836],\n",
       " [8.13858413696289, 4.163808822631836],\n",
       " [8.13858413696289, 4.163808822631836],\n",
       " [8.13858413696289, 4.163808822631836],\n",
       " [8.13858413696289, 4.163808822631836],\n",
       " [7.888584136962891, 4.163808822631836],\n",
       " [7.888584136962891, 4.163808822631836],\n",
       " [7.888584136962891, 4.163808822631836],\n",
       " [7.888584136962891, 4.163808822631836],\n",
       " [7.888584136962891, 4.163808822631836],\n",
       " [7.638584136962891, 4.163808822631836],\n",
       " [7.638584136962891, 4.163808822631836],\n",
       " [7.638584136962891, 4.163808822631836],\n",
       " [7.388584136962891, 4.163808822631836],\n",
       " [7.138584136962891, 4.163808822631836],\n",
       " [6.888584136962891, 4.163808822631836],\n",
       " [6.638584136962891, 4.163808822631836],\n",
       " [6.388584136962891, 4.163808822631836],\n",
       " [6.138584136962891, 4.163808822631836],\n",
       " [5.888584136962891, 4.163808822631836],\n",
       " [5.638584136962891, 4.163808822631836],\n",
       " [5.388584136962891, 4.163808822631836],\n",
       " [5.138584136962891, 4.163808822631836],\n",
       " [4.888584136962891, 4.163808822631836],\n",
       " [4.638584136962891, 4.163808822631836],\n",
       " [4.388584136962891, 4.163808822631836],\n",
       " [4.138584136962891, 4.163808822631836],\n",
       " [3.8885841369628906, 4.163808822631836],\n",
       " [3.6385841369628906, 4.163808822631836],\n",
       " [3.3885841369628906, 4.163808822631836],\n",
       " [3.3885841369628906, 4.163808822631836],\n",
       " [3.3885841369628906, 4.163808822631836],\n",
       " [3.1385841369628906, 4.163808822631836],\n",
       " [2.8885841369628906, 4.163808822631836],\n",
       " [2.6385841369628906, 4.163808822631836],\n",
       " [2.3885841369628906, 4.163808822631836],\n",
       " [2.3885841369628906, 4.163808822631836],\n",
       " [2.1720778942108154, 4.038808822631836],\n",
       " [2.1720778942108154, 4.038808822631836],\n",
       " [1.9220778942108154, 4.038808822631836],\n",
       " [1.6720778942108154, 4.038808822631836],\n",
       " [1.4220778942108154, 4.038808822631836],\n",
       " [1.1720778942108154, 4.038808822631836],\n",
       " [1.1720778942108154, 4.038808822631836],\n",
       " [0.9555715322494507, 4.163808822631836],\n",
       " [0.7390651702880859, 4.288808822631836],\n",
       " [0.5225588083267212, 4.413808822631836],\n",
       " [0.5225588083267212, 4.413808822631836],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.3975587785243988, 4.63031530380249],\n",
       " [0.6475588083267212, 4.63031530380249],\n",
       " [0.8975588083267212, 4.63031530380249],\n",
       " [1.1475588083267212, 4.63031530380249],\n",
       " [1.3975588083267212, 4.63031530380249],\n",
       " [1.6475588083267212, 4.63031530380249],\n",
       " [1.8975588083267212, 4.63031530380249],\n",
       " [2.1475586891174316, 4.63031530380249],\n",
       " [2.3975586891174316, 4.63031530380249],\n",
       " [2.6475586891174316, 4.63031530380249],\n",
       " [2.8975586891174316, 4.63031530380249],\n",
       " [3.1475586891174316, 4.63031530380249],\n",
       " [3.3975586891174316, 4.63031530380249],\n",
       " [3.6475586891174316, 4.63031530380249],\n",
       " [3.8975586891174316, 4.63031530380249],\n",
       " [4.147558689117432, 4.63031530380249],\n",
       " [4.397558689117432, 4.63031530380249],\n",
       " [4.647558689117432, 4.63031530380249],\n",
       " [4.897558689117432, 4.63031530380249],\n",
       " [5.147558689117432, 4.63031530380249],\n",
       " [5.397558689117432, 4.63031530380249],\n",
       " [5.647558689117432, 4.63031530380249],\n",
       " [5.897558689117432, 4.63031530380249],\n",
       " [6.147558689117432, 4.63031530380249],\n",
       " [6.397558689117432, 4.63031530380249],\n",
       " [6.647558689117432, 4.63031530380249],\n",
       " [6.897558689117432, 4.63031530380249],\n",
       " [7.147558689117432, 4.63031530380249],\n",
       " [7.397558689117432, 4.63031530380249],\n",
       " [7.647558689117432, 4.63031530380249],\n",
       " [7.897558689117432, 4.63031530380249],\n",
       " [7.897558689117432, 4.63031530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [8.114065170288086, 4.50531530380249],\n",
       " [7.864065170288086, 4.50531530380249],\n",
       " [7.614065170288086, 4.50531530380249],\n",
       " [7.364065170288086, 4.50531530380249],\n",
       " [7.364065170288086, 4.50531530380249],\n",
       " [7.147558689117432, 4.63031530380249],\n",
       " [7.147558689117432, 4.63031530380249]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cons import ACTIONS\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import imageio\n",
    "\n",
    "\n",
    "def inference(get_distribution: Callable[[torch.Tensor, ActorCritic], torch.distributions.Categorical], init_position: dict[str, float], env: Env, actor_critic: ActorCritic, plot=True):\n",
    "    n = 256\n",
    "    n_row = 32\n",
    "    positions = []\n",
    "\n",
    "    plt.figure(figsize=(n // n_row * 2, n_row * 2))\n",
    "    event = teleport(controller, init_position)\n",
    "    episode_seq = deque(maxlen=EPISODE_STEPS)\n",
    "    actions_seq = deque(maxlen=EPISODE_STEPS)\n",
    "    raw_obs = []\n",
    "    for t in range(1, n + 1):\n",
    "        positions.append([event.metadata[\"agent\"][\"position\"][\"x\"], event.metadata[\"agent\"][\"position\"][\"z\"]])\n",
    "        with torch.no_grad():\n",
    "            obs_t = ppo.obs_from_event(event)  # (C,H,W)\n",
    "            obs_t_encoded = actor_critic.actor_critic_encoder(obs_t.unsqueeze(0).unsqueeze(0)).squeeze(0).squeeze(0)\n",
    "            obs_seq = torch.stack(list(episode_seq) + [obs_t_encoded], dim=0).unsqueeze(0).to(device=DEVICE)\n",
    "\n",
    "        if len(actions_seq) == 0:\n",
    "            actions_seq.append(torch.randint(0, NUM_ACTIONS, (1, 1)).item())\n",
    "        \n",
    "        actions_tensor = torch.tensor(actions_seq, dtype=torch.long, device=DEVICE).unsqueeze(0)\n",
    "        dist = get_distribution(obs_seq, actions_tensor, actor_critic)\n",
    "        action_idx = dist.sample()\n",
    "        logp = dist.log_prob(action_idx)\n",
    "        \n",
    "        action_idx, logp = action_idx.item(), logp.item()\n",
    "        event, reward = env.step_env(controller, action_idx)\n",
    "\n",
    "        # store one step\n",
    "        episode_seq.append(obs_t_encoded)\n",
    "        actions_seq.append(action_idx)\n",
    "        raw_obs.append(obs_t)\n",
    "        \n",
    "        if plot:\n",
    "            # Plot frame and action\n",
    "            plt.subplot(n_row, n // n_row, t)\n",
    "            plt.title(\"action: \" + ACTIONS[action_idx] + \", r: \" + f\"{reward:.2f}\" + \"\\n, prob = \" + f\"{torch.exp(dist.log_prob(torch.tensor([0, 1, 2], device=DEVICE))).cpu().numpy()}\", fontsize=5)\n",
    "            plt.axis(False)\n",
    "            plt.imshow(event.frame)\n",
    "    if plot:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ---- Plot 2D trajectory of the agent ----\n",
    "        positions = np.array(positions)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.plot(positions[:, 0], positions[:, 1], \"-o\", markersize=3)\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"z\")\n",
    "        plt.title(\"Agent trajectory over n steps\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    return raw_obs\n",
    "\n",
    "def inference_video_mp4(\n",
    "    get_distribution,\n",
    "    init_position: dict[str, float],\n",
    "    env: Env,\n",
    "    actor_critic: ActorCritic,\n",
    "    video_path=\"rollout.mp4\",\n",
    "    fps=10,\n",
    "    n_steps=256\n",
    "):\n",
    "    episode_seq = deque(maxlen=EPISODE_STEPS)\n",
    "    actions_seq = deque(maxlen=EPISODE_STEPS)\n",
    "\n",
    "    writer = imageio.get_writer(video_path, fps=fps)\n",
    "\n",
    "    # start episode\n",
    "    event = teleport(controller, init_position)\n",
    "    positions = []\n",
    "\n",
    "    for t in range(1, n_steps + 1):\n",
    "\n",
    "        # ---- Add current frame to video ----\n",
    "        writer.append_data(event.frame[:, :, ::-1])   # convert RGBâ†’BGR if needed\n",
    "\n",
    "        # track positions\n",
    "        positions.append([\n",
    "            event.metadata[\"agent\"][\"position\"][\"x\"],\n",
    "            event.metadata[\"agent\"][\"position\"][\"z\"],\n",
    "        ])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            obs_t = ppo.obs_from_event(event)  \n",
    "            obs_enc = actor_critic.actor_critic_encoder(\n",
    "                obs_t.unsqueeze(0).unsqueeze(0)\n",
    "            ).squeeze(0).squeeze(0)\n",
    "\n",
    "            obs_seq = torch.stack(\n",
    "                list(episode_seq) + [obs_enc], dim=0\n",
    "            ).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # ---- Action ----\n",
    "        if len(actions_seq) == 0:\n",
    "            actions_seq.append(torch.randint(0, NUM_ACTIONS, ()).item())\n",
    "\n",
    "        actions_tensor = torch.tensor(\n",
    "            actions_seq, dtype=torch.long, device=DEVICE\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        dist = get_distribution(obs_seq, actions_tensor, actor_critic)\n",
    "        action_idx = dist.sample().item()\n",
    "\n",
    "        # ---- Step env ----\n",
    "        event, reward = env.step_env(controller, action_idx)\n",
    "\n",
    "        # ---- Store ----\n",
    "        episode_seq.append(obs_enc)\n",
    "        actions_seq.append(action_idx)\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"[ðŸŽžï¸] Saved video to {video_path}\")\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "def get_distributions(obs_seq, actions_tensor, clip_actor_critic):\n",
    "    logits, value = ppo.act_and_value(obs_seq, actions_tensor, clip_actor_critic)\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    return dist\n",
    "\n",
    "event = teleport(controller)\n",
    "init_pos = event.metadata[\"agent\"][\"position\"]\n",
    "inference_video_mp4(get_distributions, init_pos, clip_env, clip_actor_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23ba3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /home/juyuanli/miniconda3/envs/nav_assistant/lib/python3.11/site-packages (2.37.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/juyuanli/miniconda3/envs/nav_assistant/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy in /home/juyuanli/miniconda3/envs/nav_assistant/lib/python3.11/site-packages (from imageio) (2.0.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/juyuanli/miniconda3/envs/nav_assistant/lib/python3.11/site-packages (from imageio) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a46bc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae83af17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: 0.877001953125\n",
      "Rand: 0.86337890625\n",
      "Policy: 0.87021484375\n",
      "Rand: 0.8068359375\n",
      "Policy: 0.83388671875\n",
      "Rand: 0.845361328125\n",
      "Policy: 0.8791015625\n",
      "Rand: 0.876318359375\n",
      "Policy: 0.80693359375\n",
      "Rand: 0.79033203125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x6400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def preprocess_clip(x):\n",
    "    # Resize to CLIP resolution\n",
    "    x = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "    # Normalize (CLIP standard mean/std)\n",
    "    mean = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=x.device).view(1, 3, 1, 1)\n",
    "    std  = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=x.device).view(1, 3, 1, 1)\n",
    "    return (x - mean) / std\n",
    "\n",
    "def get_average(input_img):\n",
    "    # ---- 1. Sample 50 random images ----\n",
    "    n = min(50, len(input_img))\n",
    "    indices = random.sample(range(len(input_img)), n)\n",
    "    imgs = torch.stack([input_img[i] for i in indices]).to(DEVICE)  # (50, 3, H, W)\n",
    "\n",
    "    # ---- 2. Preprocess for CLIP ----\n",
    "    imgs_clip = preprocess_clip(imgs).half()  # normalized, resized\n",
    "\n",
    "    # ---- 3. Encode with CLIP visual encoder ----\n",
    "    with torch.no_grad():\n",
    "        embeds = model.visual(imgs_clip)       # (50, D)\n",
    "        embeds = embeds / embeds.norm(dim=-1, keepdim=True)  # normalize to unit sphere\n",
    "\n",
    "    # ---- 4. Compute cosine similarity ----\n",
    "    sim_matrix = embeds @ embeds.T             # (50, 50)\n",
    "    # Optional: remove self-similarity (diagonal = 1)\n",
    "    sim_matrix.fill_diagonal_(0)\n",
    "\n",
    "    # ---- 5. Summary statistics ----\n",
    "    mean_sim = sim_matrix.mean().item()\n",
    "\n",
    "    return mean_sim\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    event = teleport(controller)\n",
    "    init_pos = event.metadata[\"agent\"][\"position\"]\n",
    "    \n",
    "    def get_distributions(obs_seq, actions_tensor, clip_actor_critic):\n",
    "        logits, value = ppo.act_and_value(obs_seq, actions_tensor, clip_actor_critic)\n",
    "        dist = torch.distributions.Categorical(logits=logits)\n",
    "        return dist\n",
    "\n",
    "    policy = inference(get_distributions, init_pos, clip_env, clip_actor_critic, False)\n",
    "\n",
    "    def get_distributions(obs_seq, actions_tensor, clip_actor_critic):\n",
    "        dist = torch.distributions.Categorical(probs=torch.tensor([0.5, 0.25, 0.25], device=DEVICE))\n",
    "        return dist\n",
    "\n",
    "    rand_policy = inference(get_distributions, init_pos, clip_env, clip_actor_critic, False)\n",
    "\n",
    "    mean_policies = []\n",
    "    mean_rands = []\n",
    "    for i in range(10):\n",
    "        mean_policy = get_average(policy)\n",
    "        mean_rand = get_average(rand_policy)\n",
    "        mean_policies.append(mean_policy)\n",
    "        mean_rands.append(mean_rand)\n",
    "    \n",
    "    print(\"Policy: \" + str(np.mean(np.array(mean_policies))))\n",
    "    print(\"Rand: \" + str(np.mean(np.array(mean_rands))))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
